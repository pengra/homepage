Modern theoretical computer science research is based on these basic developments, but includes many other mathematical and interdisciplinary problems that have been posed, as shown below: Information-based complexity (IBC) studies optimal algorithms and computational complexity for continuous problems. IBC has studied continuous problems as path integration, partial differential equations, systems of ordinary differential equations, nonlinear equations, integral equations, fixed points, and very-high-dimensional integration. Theoretical results in machine learning mainly deal with a type of inductive learning called supervised learning.  In supervised learning, an algorithm is given samples that are labeled in some useful way.  For example, the samples might be descriptions of mushrooms, and the labels could be whether or not the mushrooms are edible.  The algorithm takes these previously labeled samples and uses them to induce a classifier.  This classifier is a function that assigns labels to samples including the samples that have never been previously seen by the algorithm.  The goal of the supervised learning algorithm is to optimize some measure of performance such as minimizing the number of mistakes made on new samples.