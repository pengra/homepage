This chapter continues to present programming concepts by example, in the context of a linguistic processing task.  We will wait until later before exploring each Python construct systematically.  Don't worry if you see an example that contains something unfamiliar; simply try it out and see what it does, and — if you're game — modify it by substituting some part of the code with a different text or word.  This way you will associate a task with a programming idiom, and learn the hows and whys later. Note Note Example Document for Each Section of the Brown Corpus We can access the corpus as a list of words, or a list of sentences (where each sentence is itself just a list of words).  We can optionally specify particular categories or files to read: Note Note Unlike the Brown Corpus, categories in the Reuters corpus overlap with each other, simply because a news story often covers multiple topics. We can ask for the topics covered by one or more documents, or for the documents included in one or more categories. For convenience, the corpus methods accept a single fileid or a list of fileids. Similarly, we can specify the words or sentences we want in terms of files or categories. The first handful of words in each of these texts are the titles, which by convention are stored as upper case. Some of the Corpora and Corpus Samples Distributed with NLTK: For information about downloading and using them, please consult the NLTK website. Note Let's access the two conditions, and satisfy ourselves that each is just a frequency distribution: Note NLTK's Conditional Frequency Distributions: commonly-used methods and idioms for defining, accessing, and visualizing a conditional frequency distribution of counters. By this time you've probably typed and retyped a lot of code in the Python interactive interpreter.  If you mess up when retyping a complex example you have to enter it again.  Using the arrow keys to access and modify previous commands is helpful but only goes so far.  In this section we see two important ways to reuse code: text editors and Python functions. Note Suppose that you work on analyzing text that involves different forms of the same word, and that part of your program needs to work out the plural form of a given singular noun.  Suppose it needs to do this work in two places, once when it is processing some texts, and again when it is processing user input. Over time you will find that you create a variety of useful little text processing functions, and you end up copying them from old programs to new ones.  Which file contains the latest version of the function you want to use? It makes life a lot easier if you can collect your work into a single place, and access previously defined functions without making copies. Caution! The simplest kind of lexicon is nothing more than a sorted list of words. Sophisticated lexicons include complex structure within and across the individual entries.  In this section we'll look at some lexical resources included with NLTK. Thus, with the help of stopwords we filter out over a quarter of the words of the text. Notice that we've combined two different kinds of corpus here, using a lexical resource to filter the content of a text corpus. One more wordlist corpus is the Names corpus, containing 8,000 first names categorized by gender. The male and female names are stored in separate files.  Let's find names which appear in both files, i.e. names that are ambiguous for gender: A slightly richer kind of lexical resource is a table (or spreadsheet), containing a word plus some properties in each row.  NLTK includes the CMU Pronouncing Dictionary for US English, which was designed for use by speech synthesizers. Note We can use any lexical resource to process a text, e.g., to filter out words having some lexical property (like nouns), or mapping every word of the text. For example, the following text-to-speech function looks up each word of the text in the pronunciation dictionary. We can compare words in various Germanic and Romance languages: A Toolbox file consists of a collection of entries, where each entry is made up of one or more fields. Most fields are optional or repeatable, which means that this kind of lexical resource cannot be treated as a table or spreadsheet. Note Note We can get the most general hypernyms (or root hypernyms) of a synset as follows: Note Note About this document... This document was built on Mon  1 Apr 2019 20:30:15 ACST