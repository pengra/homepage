ð SLAO blog SLAO Developers Team Â· 2019.03.28 The first thing we thought of was “now we need a proper monitoring, we canât f*ck this up, not now” Weâd never seriously dealt with monitoring of REST APIs before, so we started to discover the subject. So, how can we monitor our REST API? It turned out there were (and still is) three main approaches to do this: Using a front-end analytics in back-end doesnât look like a good idea at all, so we decided to omit the 4th approach. Letâs figure out what we need to monitor in the first place, Iâll base this on our SLA terms. The obvious but worth mentioning thing is that we have to be able to set up alerts related to these metrics. Here is the dashboard we created (please, donât let Russian symbols scary you, I didnât mean this): At first glance this solution looked like exactly what we needed: However, we had to invent everything from scratch, so we had to find answers to next questions: You can see that thereâs plenty of space to mess up the whole thing by missing a tiny, but crucial point, e.g. a small error in metrics collection may lead to huge troubles, unfortunately we had such experience, weâll publish an article about this a bit later. To finally kill the idea of developing your own monitoring tool, there are more issues related to it: It looks so nice, and itâs not overloaded with functions youâll never use, it took me 5 minutes to set it up, below is the dashboard I created: However, you canât rely solely on this monitoring because these metrics have nothing to do with the actual clientsâ experience. Your API may respond fast and correctly to these pings from the outside, but thereâs always a chance it performs terrible with your clientsâ data, and youâll never know this. Thatâs why we had to turn down this approach and use a tool that monitors the metrics of actual customersâ interaction with our REST API. We considered the most popular solutions: New Relic APM and Elastic Cloud APM. Letâs describe both of them in details. New Relic APM I signed up for New Relic APM trial, added their agent into our REST API and started setting it up. The default New Relic APM functionality includes everything you might ever need (and unfortunately much more), Iâm not going to waste your time describing all its features, you can check them out on the official website. Instead, letâs focus on how useful (or not) it is for REST API monitoring. First of all, I found the default New Relic APM dashboards too overloaded but missing features I wanted to see in the first place, such as response codes. I didnât need so detailed breakdown of every call of my app, I know what it does and what resources it uses, I programmed it myself, for godâs sake! Here is one of the default New Relic APM dashboards: The only thing that may let you down is that you canât group the data by custom attributes since theyâre not indexed, I had to use custom events to record all the metrics I need. Here is the dashboard I created after half an hour (sorry for Russian, again): My dreams were ruined and I signed up for Elastic Cloud APM trial. Elastic APM I signed up for the cloud version - AWS based ElasticSearch + Elastic APM + Kibana stack, the setup process is not as smooth as New Relicâs, though thereâs nothing complicated about it. It took me about 15 minutes to set it up. The agent is also similar to New Relicâs one in terms of integration - nothing to be bothered with. Default APM dashboards look identical to New Relicâs, maybe a bit less overloaded, but the whole impression is the same: you canât use it for REST API monitoring out of the box, at least when you have to comply with strict SLA terms. Here is one of the default Elastic APM dashboards: So I started creating a custom dashboard with Kibana. Event though I had a strong background with ElasticSearch, I was struggling with Kibana for almost a whole day, it took me about 5 hours to finally create a dashboard with all the data I needed. It turned out to be much more complicated than New Relic Insights. Here is the dashboard I made: So, the dashboard is ready, letâs move to setting up the alerts. Each alert is configured with a JSON object including query, threshold and actions descriptions. Below is an alert that notifies us about calls of our service that took more than 10 seconds to complete: Pretty complicated, right? Now imagine having 15 JSONs like this, managing them is pure hell. Whatâs more, you canât segregate your alerts by applications or hosts, you always have to include these terms into the query within the alert JSON. This creates a huge space for making a mistake, missing a crucial incident and f*cking up everything. Nevertheless, Elastic Cloud was the only solution that matched all our requirements. It does not limit your data retention - you can use all the space you paid for, also I managed to create useful dashboard and to set up all the alerts I needed. So we decided to stick with Elastic Cloud for a while. The story doesnât end here. Weâd been using Elastic Cloud for about a month, the lack of ability to create and manage alerts without pain and suffer along with complicated Kibanaâs dashboard management was driving us mad.